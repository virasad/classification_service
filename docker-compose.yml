version: "3.8"
services:
  inference:
        # network_mode: host
    container_name: "classification-inference"
    build: "./inference"
    command: "python3 main.py"
    ports:
        - "5556:5556"
    volumes:
        - ./inference:/code
        - ./volumes/weights:/weights

    environment:
        - PORT=5556
        - WEIGHTS_DIR=/weights
    deploy:
        resources:
            reservations:
                devices:
                    - capabilities: [gpu]

  train:
      # network_mode: host
    container_name: "classification-train"
    build: "./train"
    command: "python3 main.py"
    ports:
        - "5554:5554"
    volumes:
        - ./train:/code
        - ./volumes/weights:/weights
        - ./volumes/dataset:/dataset
    environment:
        - RESPONSE_URL=http://web:8000/api/v1/train/done
        - LOGGER_URL=http://127.0.0.1:8000/logger
        - PORT=5554
        - IS_LOGGER_ON=False
    deploy:
        resources:
            reservations:
                devices:
                    - capabilities: [gpu]
